{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4fbc879-5440-49e3-bf62-f8b1a1c4bf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.1.24-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.1.24-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m161.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (391 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, markdown, grpcio, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.1.24 gast-0.6.0 grpcio-1.70.0 keras-3.8.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e65530-0464-4a1f-9291-9b008c119615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/25 16:38:45] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Skipping checksum validation. Response did not contain one of the  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">httpchecksum.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py#481\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         following algorithms: <span style=\"font-weight: bold\">[</span><span style=\"color: #008700; text-decoration-color: #008700\">'crc32'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha1'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha256'</span><span style=\"font-weight: bold\">]</span>.                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/25 16:38:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Skipping checksum validation. Response did not contain one of the  \u001b]8;id=865884;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py\u001b\\\u001b[2mhttpchecksum.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=179264;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py#481\u001b\\\u001b[2m481\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         following algorithms: \u001b[1m[\u001b[0m\u001b[38;2;0;135;0m'crc32'\u001b[0m, \u001b[38;2;0;135;0m'sha1'\u001b[0m, \u001b[38;2;0;135;0m'sha256'\u001b[0m\u001b[1m]\u001b[0m.                 \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding for datasets1/re_dataset.csv: ISO-8859-1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Skipping checksum validation. Response did not contain one of the  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">httpchecksum.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py#481\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         following algorithms: <span style=\"font-weight: bold\">[</span><span style=\"color: #008700; text-decoration-color: #008700\">'crc32'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha1'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha256'</span><span style=\"font-weight: bold\">]</span>.                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Skipping checksum validation. Response did not contain one of the  \u001b]8;id=916575;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py\u001b\\\u001b[2mhttpchecksum.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=629911;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py#481\u001b\\\u001b[2m481\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         following algorithms: \u001b[1m[\u001b[0m\u001b[38;2;0;135;0m'crc32'\u001b[0m, \u001b[38;2;0;135;0m'sha1'\u001b[0m, \u001b[38;2;0;135;0m'sha256'\u001b[0m\u001b[1m]\u001b[0m.                 \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Skipping checksum validation. Response did not contain one of the  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">httpchecksum.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py#481\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         following algorithms: <span style=\"font-weight: bold\">[</span><span style=\"color: #008700; text-decoration-color: #008700\">'crc32'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha1'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha256'</span><span style=\"font-weight: bold\">]</span>.                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Skipping checksum validation. Response did not contain one of the  \u001b]8;id=278619;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py\u001b\\\u001b[2mhttpchecksum.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=275512;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py#481\u001b\\\u001b[2m481\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         following algorithms: \u001b[1m[\u001b[0m\u001b[38;2;0;135;0m'crc32'\u001b[0m, \u001b[38;2;0;135;0m'sha1'\u001b[0m, \u001b[38;2;0;135;0m'sha256'\u001b[0m\u001b[1m]\u001b[0m.                 \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding for datasets1/new_kamusalay.csv: ISO-8859-1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/25 16:38:46] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Skipping checksum validation. Response did not contain one of the  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">httpchecksum.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py#481\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         following algorithms: <span style=\"font-weight: bold\">[</span><span style=\"color: #008700; text-decoration-color: #008700\">'crc32'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha1'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha256'</span><span style=\"font-weight: bold\">]</span>.                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/25 16:38:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Skipping checksum validation. Response did not contain one of the  \u001b]8;id=91199;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py\u001b\\\u001b[2mhttpchecksum.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=164308;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py#481\u001b\\\u001b[2m481\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         following algorithms: \u001b[1m[\u001b[0m\u001b[38;2;0;135;0m'crc32'\u001b[0m, \u001b[38;2;0;135;0m'sha1'\u001b[0m, \u001b[38;2;0;135;0m'sha256'\u001b[0m\u001b[1m]\u001b[0m.                 \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Skipping checksum validation. Response did not contain one of the  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">httpchecksum.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py#481\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         following algorithms: <span style=\"font-weight: bold\">[</span><span style=\"color: #008700; text-decoration-color: #008700\">'crc32'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha1'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha256'</span><span style=\"font-weight: bold\">]</span>.                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Skipping checksum validation. Response did not contain one of the  \u001b]8;id=711789;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py\u001b\\\u001b[2mhttpchecksum.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=375598;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py#481\u001b\\\u001b[2m481\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         following algorithms: \u001b[1m[\u001b[0m\u001b[38;2;0;135;0m'crc32'\u001b[0m, \u001b[38;2;0;135;0m'sha1'\u001b[0m, \u001b[38;2;0;135;0m'sha256'\u001b[0m\u001b[1m]\u001b[0m.                 \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding for datasets1/abusive.csv: ascii\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/25 16:38:47] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Skipping checksum validation. Response did not contain one of the  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">httpchecksum.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py#481\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         following algorithms: <span style=\"font-weight: bold\">[</span><span style=\"color: #008700; text-decoration-color: #008700\">'crc32'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha1'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha256'</span><span style=\"font-weight: bold\">]</span>.                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/25 16:38:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Skipping checksum validation. Response did not contain one of the  \u001b]8;id=497295;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py\u001b\\\u001b[2mhttpchecksum.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=171250;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/httpchecksum.py#481\u001b\\\u001b[2m481\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         following algorithms: \u001b[1m[\u001b[0m\u001b[38;2;0;135;0m'crc32'\u001b[0m, \u001b[38;2;0;135;0m'sha1'\u001b[0m, \u001b[38;2;0;135;0m'sha256'\u001b[0m\u001b[1m]\u001b[0m.                 \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-02-07 16:41:03.473931: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m 66/330\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.5794 - loss: 0.6767"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from io import StringIO\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, LSTM, Dense, Dropout, SpatialDropout1D, Input, Concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import chardet\n",
    "\n",
    "# Define S3 bucket and file paths\n",
    "s3_bucket = \"basehatespeech\"\n",
    "s3_data_path = \"s3://basehatespeech/datasets1/re_dataset.csv\"\n",
    "s3_slang_path = \"s3://basehatespeech/datasets1/new_kamusalay.csv\"\n",
    "s3_abusive_path = \"s3://basehatespeech/datasets1/abusive.csv\"\n",
    "\n",
    "# Load datasets from S3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Function to detect file encoding\n",
    "def detect_encoding(bucket, key):\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    raw_data = obj['Body'].read(100000)  # Read first 100KB for detection\n",
    "    result = chardet.detect(raw_data)\n",
    "    return result['encoding']\n",
    "\n",
    "# Function to load CSV from S3 with encoding detection\n",
    "def load_s3_csv(bucket, key):\n",
    "    encoding = detect_encoding(bucket, key)  # Detect encoding\n",
    "    print(f\"Detected encoding for {key}: {encoding}\")\n",
    "\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    data = obj['Body'].read().decode(encoding, errors='replace')  # Replace invalid characters\n",
    "    return pd.read_csv(StringIO(data))\n",
    "\n",
    "# Load datasets\n",
    "df = load_s3_csv(s3_bucket, \"datasets1/re_dataset.csv\")\n",
    "kamusalay = load_s3_csv(s3_bucket, \"datasets1/new_kamusalay.csv\")\n",
    "abusive_words = set(load_s3_csv(s3_bucket, \"datasets1/abusive.csv\")[\"ABUSIVE\"].tolist())\n",
    "\n",
    "# Preprocessing\n",
    "kamus_dict = dict(zip(kamusalay.iloc[:, 0], kamusalay.iloc[:, 1]))\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    for slang, standard in kamus_dict.items():\n",
    "        text = text.replace(slang, standard)\n",
    "    return text\n",
    "\n",
    "df['cleaned_tweet'] = df['Tweet'].apply(preprocess_text)\n",
    "df['contains_abusive'] = df['cleaned_tweet'].apply(lambda text: int(any(word in abusive_words for word in text.split())))\n",
    "\n",
    "# Tokenization\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['cleaned_tweet'])\n",
    "sequences = tokenizer.texts_to_sequences(df['cleaned_tweet'])\n",
    "X_text = pad_sequences(sequences, maxlen=max_len)\n",
    "X_extra = np.array(df[['contains_abusive']])\n",
    "\n",
    "# Encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['HS'])\n",
    "\n",
    "# Split data\n",
    "X_text_train, X_text_test, X_extra_train, X_extra_test, y_train, y_test = train_test_split(X_text, X_extra, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model\n",
    "text_input = Input(shape=(max_len,), name=\"text_input\")\n",
    "extra_input = Input(shape=(1,), name=\"extra_input\")\n",
    "embedding = Embedding(input_dim=max_words, output_dim=128, input_length=max_len)(text_input)\n",
    "dropout = SpatialDropout1D(0.2)(embedding)\n",
    "conv = Conv1D(64, kernel_size=5, activation='relu', padding='same')(dropout)\n",
    "lstm = LSTM(64, return_sequences=False)(conv)\n",
    "extra_dense = Dense(16, activation='relu')(extra_input)\n",
    "merged = Concatenate()([lstm, extra_dense])\n",
    "dense = Dense(64, activation='relu')(merged)\n",
    "dropout_final = Dropout(0.5)(dense)\n",
    "out = Dense(1, activation='sigmoid')(dropout_final)\n",
    "model = Model(inputs=[text_input, extra_input], outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit([X_text_train, X_extra_train], y_train, validation_data=([X_text_test, X_extra_test], y_test), epochs=5, batch_size=32)\n",
    "\n",
    "# Save model locally\n",
    "model.save(\"hate_speech_cnn_rnn_model.h5\")\n",
    "print(\"Model saved locally as hate_speech_cnn_rnn_model.h5\")\n",
    "\n",
    "# Upload model to S3\n",
    "model_s3_path = f\"s3://{s3_bucket}/models/hate_speech_cnn_rnn_model.h5\"\n",
    "s3.upload_file(\"hate_speech_cnn_rnn_model.h5\", s3_bucket, \"models/hate_speech_cnn_rnn_model.h5\")\n",
    "print(f\"Model uploaded to {model_s3_path}\")\n",
    "\n",
    "# Upload processed data to S3\n",
    "train_data_path = f\"s3://{s3_bucket}/train/\"\n",
    "test_data_path = f\"s3://{s3_bucket}/test/\"\n",
    "\n",
    "np.save(\"X_text_train.npy\", X_text_train)\n",
    "s3.upload_file(\"X_text_train.npy\", s3_bucket, \"train/X_text_train.npy\")\n",
    "np.save(\"X_extra_train.npy\", X_extra_train)\n",
    "s3.upload_file(\"X_extra_train.npy\", s3_bucket, \"train/X_extra_train.npy\")\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "s3.upload_file(\"y_train.npy\", s3_bucket, \"train/y_train.npy\")\n",
    "\n",
    "np.save(\"X_text_test.npy\", X_text_test)\n",
    "s3.upload_file(\"X_text_test.npy\", s3_bucket, \"test/X_text_test.npy\")\n",
    "np.save(\"X_extra_test.npy\", X_extra_test)\n",
    "s3.upload_file(\"X_extra_test.npy\", s3_bucket, \"test/X_extra_test.npy\")\n",
    "np.save(\"y_test.npy\", y_test)\n",
    "s3.upload_file(\"y_test.npy\", s3_bucket, \"test/y_test.npy\")\n",
    "\n",
    "# Define SageMaker training job\n",
    "role = sagemaker.get_execution_role()\n",
    "estimator = TensorFlow(\n",
    "    entry_point='train_script.py',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    framework_version='2.8',\n",
    "    py_version='py39',\n",
    "    hyperparameters={\n",
    "        'epochs': 5,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    output_path=f's3://{s3_bucket}/output/'\n",
    ")\n",
    "\n",
    "# Start training\n",
    "estimator.fit({\n",
    "    'train': TrainingInput(train_data_path),\n",
    "    'test': TrainingInput(test_data_path)\n",
    "})\n",
    "\n",
    "print(\"SageMaker training job started!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a053ae-33e8-4edd-88a6-555bb17ea144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
